### use # to comment out the configure item

###
task_name=ned

### prepare_data ###
data_bin_dir=data/data.pickle
train_dir=data/ned.train
dev_dir=data/ned.testa
test_dir=data/ned.testb
trans_dir=data/nl-en.txt
word_emb_dir=data/wiki.nl.vec
trans_embed_dir=data/glove.6B.100d.txt
middle_dir=../data-middle/
viterbi_inputs_model_name=lrner



### base of lrner ###
#typeinfo_dir=
#model_name=lstmcrf=
model_dir=save-substring/
norm_word_emb=False
norm_char_emb=False
word_emb_dim=300
char_emb_dim=30
trans_emb_dim=100

#raw_dir=
#decode_dir=
#dset_dir=
#load_model_dir=
#char_emb_dir=

number_normalized=True
seg=True

###NetworkConfiguration###
use_crf=True
use_char=True
use_trans=True
#use_mapping=True
#mapping_func=tanh
word_seq_feature=LSTM
char_seq_feature=LSTM
feature=feature_1 emb_size=30 emb_norm=False emb_dir=data/ned_pos.vector30
#feature=[Cap] emb_size=20
nbest=1

###TrainingSetting###
status=train
state_training_name=default
save_model=False
optimizer=SGD
iteration=600
batch_size=16
ave_batch_loss=False
show_loss_per_batch=100

###Hyperparameters###
# if seed_num is None, it will rand a int
seed_num=None
cnn_layer=4
char_hidden_dim=50
trans_hidden_dim=200
hidden_dim=200
dropout=0.5
lstm_layer=2
bilstm=True
learning_rate=0.015
lr_decay=0.05
momentum=0
l2=1e-8
gpu=True
# if clip is None, it will be no clip
clip=None


###Base2###
substring_dir=data/substring/
bpe_emb_dir=None
pos_emb_dir=None
feature_name=word
feature_length=3
class_num=2
#ORG,PER,MISC,LOC
#S,R,M,W
feature_ans=ORG

###circul###
circul_time=4
circul_deepth=2
circul_gather_output_mode=concat

###warmup###
warmup_step=100
warmup_begain=0.001
warmup_raise=0.001
warmup_decay=0.05

###decode_prepare###
decode_prepare_mode=example